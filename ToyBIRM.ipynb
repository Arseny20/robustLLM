{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:47:20.197799Z",
     "start_time": "2025-07-23T04:47:20.192617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cpu'"
   ],
   "id": "7a862449f0a9bde9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## V1",
   "id": "592f6336cc605ee6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "1abe3fef855424f8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T04:48:43.136761Z",
     "start_time": "2025-07-23T04:48:43.124260Z"
    }
   },
   "source": [
    "def generate_dataset(pe, n_samples):\n",
    "    # Invariant features ~ N(0, I)\n",
    "    X_inv = torch.randn(n_samples, 2)\n",
    "\n",
    "    # Label Y = x1 + x2 + noise\n",
    "    noise = torch.randn(n_samples) * (0.1 ** 0.5)\n",
    "    Y = X_inv.sum(dim=1) + noise  # Shape: (n_samples,)\n",
    "\n",
    "    # Spurious features ~ N([Y, Y], pe * I)\n",
    "    mean_spurious = torch.stack([Y, Y], dim=1)\n",
    "    spurious_noise = torch.randn(n_samples, 2) * (pe ** 0.5)\n",
    "    X_env = mean_spurious + spurious_noise\n",
    "\n",
    "    # Concatenate invariant and spurious features\n",
    "    X = torch.cat([X_inv, X_env], dim=1)\n",
    "    # Reshape labels to (n_samples, 1)\n",
    "    Y = Y.unsqueeze(1)\n",
    "    return X, Y\n",
    "\n",
    "def combine_datasets(datasets):\n",
    "    X = torch.concat([dataset[0] for dataset in datasets])\n",
    "    Y = torch.concat([dataset[1] for dataset in datasets])\n",
    "    return X, Y"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:48:43.461319Z",
     "start_time": "2025-07-23T04:48:43.341069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_1 = generate_dataset(0.5, 4)\n",
    "d_2 = generate_dataset(1.0, 4)\n",
    "d_3 = generate_dataset(9.9, 4)\n",
    "comb = combine_datasets([d_1, d_2, d_3])\n",
    "d_1"
   ],
   "id": "ea5f7fc879477966",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5002, -0.8092,  0.0520,  1.2263],\n",
       "         [ 0.5710,  0.8687,  1.2774,  2.7452],\n",
       "         [-1.2138,  0.6937,  0.2596, -0.8624],\n",
       "         [ 1.6968, -0.0557,  1.0721,  3.5960]]),\n",
       " tensor([[-0.1811],\n",
       "         [ 1.6353],\n",
       "         [-0.2467],\n",
       "         [ 1.9391]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Models",
   "id": "bd6a159600e679ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:52.512770Z",
     "start_time": "2025-07-23T01:07:52.507271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "out_features = 1"
   ],
   "id": "974959c63edac4b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:54.212089Z",
     "start_time": "2025-07-23T01:07:54.207313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.lin = nn.Linear(4,out_features,bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ],
   "id": "d9abefabab6b7a47",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:55.053663Z",
     "start_time": "2025-07-23T01:07:55.047525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, mean, std, epsilon) -> None:\n",
    "        super(Classifier, self).__init__()\n",
    "        self.w = mean + std*epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.w.T)"
   ],
   "id": "c182823ab626aa39",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:56.130477Z",
     "start_time": "2025-07-23T01:07:56.120286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.m_u = torch.nn.parameter.Parameter(torch.rand(1,out_features))\n",
    "        self.std = torch.nn.parameter.Parameter(torch.rand(1,out_features))\n",
    "        torch.nn.init.uniform_(self.m_u, -1, 1)\n",
    "        torch.nn.init.uniform_(self.std, 0, 1)\n",
    "\n",
    "    def recon_loss(self, X, Y, classifier, f_e): #minimize this\n",
    "        return F.mse_loss(Y, classifier(f_e(X)))\n",
    "\n",
    "    def KL_loss(self):   #maximize this\n",
    "        return torch.sum(1 + torch.log(torch.square(self.std)) - torch.square(self.m_u) - torch.square(self.std))/2\n",
    "\n",
    "    def sample(self, epsilon=None):\n",
    "        if epsilon is None:\n",
    "            epsilon =  torch.randn_like(self.m_u).to(device)\n",
    "        return Classifier(self.m_u, self.std, epsilon)\n",
    "\n",
    "    def fit(self, X, Y, f_e, epochs):\n",
    "        optim = torch.optim.Adam([self.m_u, self.std], betas=(0.5, 0.5))\n",
    "        for _ in range(epochs):\n",
    "            loss = self.recon_loss(X, Y, self.sample(), f_e) - self.KL_loss()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()"
   ],
   "id": "f2e73c94b641bda1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "a157484f1945ac18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:27:36.134085Z",
     "start_time": "2025-07-23T01:27:36.125009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pe_train = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "pe_val = [0.4, 0.8]\n",
    "pe_test = [10, 100]\n",
    "n_samples = 500\n",
    "\n",
    "train_env = [generate_dataset(pe, n_samples) for pe in pe_train]\n",
    "train_env.append(combine_datasets(train_env))\n",
    "val_env = [generate_dataset(pe, n_samples) for pe in pe_val]\n",
    "X_val = torch.cat([x for x, _ in val_env], dim=0)\n",
    "Y_val = torch.cat([y for _, y in val_env], dim=0)\n",
    "val_env = [(X_val, Y_val)]\n",
    "test_env = [generate_dataset(pe, n_samples) for pe in pe_test]\n",
    "X_test = torch.cat([x for x, _ in test_env], dim=0)\n",
    "Y_test = torch.cat([y for _, y in test_env], dim=0)\n",
    "test_env = [(X_test, Y_test)]"
   ],
   "id": "ca7620111ed032a8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:27:41.473659Z",
     "start_time": "2025-07-23T01:27:41.471273Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "526b410090d66954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:40:47.254815Z",
     "start_time": "2025-07-23T01:38:27.085253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f_e = FeatureExtractor().to(device)\n",
    "q_u = [AutoEncoder().to(device) for _ in train_env]\n",
    "\n",
    "lamda = 5\n",
    "with tqdm(range(1000)) as tepoch:\n",
    "    for ep in tepoch:\n",
    "        # Update posteriors distribution of classifiers for each training environment\n",
    "        for q, D in zip(q_u, train_env):\n",
    "            q.fit(D[0], D[1], f_e, 20)\n",
    "\n",
    "        # Update feature extractor only\n",
    "        loss = 0\n",
    "        optim = torch.optim.Adam(f_e.parameters(), betas=(0.5, 0.5), lr=0.01)\n",
    "        for _ in range(10):\n",
    "            epsilon = torch.randn_like(q_u[-1].m_u).to(device)\n",
    "            [ loss := loss + (1+lamda)*q_u[-1].recon_loss(D[0], D[1], q_u[-1].sample(epsilon), f_e)-lamda*q.recon_loss(D[0], D[1], q.sample(epsilon), f_e)  for q, D in zip(q_u[:-1], train_env[:-1]) ]\n",
    "        loss = loss/10\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epsilon = torch.zeros_like(q_u[-1].m_u).to(device)\n",
    "        test_acc = q_u[-1].recon_loss(test_env[0][0], test_env[0][1], q_u[-1].sample(epsilon), f_e)\n",
    "        train_acc = q_u[-1].recon_loss(train_env[-1][0], train_env[-1][1], q_u[-1].sample(epsilon), f_e)\n",
    "        tepoch.set_postfix_str(f'train:{train_acc}, test:{test_acc}')\n",
    "\n",
    "        if ep%50==0:\n",
    "            print(torch.matmul(q_u[-1].m_u, f_e.lin.weight))\n",
    "            print(f_e.lin.weight)"
   ],
   "id": "8df30a13c66419ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<02:40,  6.22it/s, train:2.7753427028656006, test:3.357396125793457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1106,  0.0435, -0.0517, -0.0903]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.4330,  0.1702, -0.2025, -0.3537]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:07<02:16,  6.96it/s, train:1.4322160482406616, test:1.6862764358520508]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0146, 0.1525, 0.0614, 0.0144]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.0470, 0.4902, 0.1975, 0.0463]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:14<02:01,  7.39it/s, train:0.6221087574958801, test:1.4772703647613525]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2831, 0.3205, 0.1191, 0.0747]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.3270, 0.3702, 0.1375, 0.0863]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:20<02:02,  6.90it/s, train:0.3509792387485504, test:1.5431060791015625] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4109, 0.4140, 0.1131, 0.1216]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4270, 0.4302, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [00:28<01:50,  7.25it/s, train:0.2563991844654083, test:2.046274185180664]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4381, 0.4411, 0.1290, 0.1560]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4670, 0.4702, 0.1375, 0.1663]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:34<01:40,  7.46it/s, train:0.1273856908082962, test:3.2789905071258545] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4605, 0.4816, 0.1612, 0.1692]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5070, 0.5302, 0.1775, 0.1863]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [00:41<01:48,  6.47it/s, train:0.3417434096336365, test:1.2421739101409912] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4472, 0.4502, 0.0896, 0.1160]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4870, 0.4902, 0.0975, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [00:48<01:31,  7.12it/s, train:0.34626781940460205, test:1.2922898530960083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4446, 0.4477, 0.0929, 0.1203]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4670, 0.4702, 0.0975, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [00:55<01:23,  7.16it/s, train:0.15628857910633087, test:2.424215316772461] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4845, 0.4875, 0.1265, 0.1529]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.1375, 0.1663]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [01:03<01:16,  7.13it/s, train:0.2671554386615753, test:1.5219216346740723] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4417, 0.4627, 0.0885, 0.1146]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4870, 0.5102, 0.0975, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:10<01:11,  7.01it/s, train:0.17667031288146973, test:2.308046817779541] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4682, 0.4711, 0.1222, 0.1478]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.1375, 0.1663]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 552/1000 [01:18<01:01,  7.23it/s, train:0.18404708802700043, test:2.0895962715148926]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4972, 0.4999, 0.1334, 0.1578]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5870, 0.5902, 0.1575, 0.1863]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 602/1000 [01:24<00:52,  7.55it/s, train:0.36993879079818726, test:1.1244726181030273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4264, 0.4291, 0.0652, 0.0894]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5070, 0.5102, 0.0775, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [01:31<00:47,  7.33it/s, train:0.19690154492855072, test:1.7407044172286987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4933, 0.4964, 0.1100, 0.1183]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [01:38<00:42,  7.03it/s, train:0.24483706057071686, test:1.6063544750213623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4801, 0.4830, 0.1207, 0.1284]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5470, 0.5502, 0.1375, 0.1463]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [01:45<00:34,  7.23it/s, train:0.21476979553699493, test:1.5810916423797607]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4784, 0.4987, 0.1028, 0.1105]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5470, 0.5702, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [01:52<00:26,  7.60it/s, train:0.3476116359233856, test:0.953772783279419]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4785, 0.4812, 0.0823, 0.0897]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5670, 0.5702, 0.0975, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [01:58<00:20,  7.05it/s, train:0.1763838529586792, test:1.5947726964950562] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5211, 0.5240, 0.1043, 0.1122]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5870, 0.5902, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [02:05<00:13,  7.23it/s, train:0.25676387548446655, test:1.0496997833251953]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5283, 0.5314, 0.0942, 0.1027]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5470, 0.5502, 0.0975, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [02:13<00:07,  6.76it/s, train:0.22807025909423828, test:1.3618232011795044]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4993, 0.5024, 0.0924, 0.1007]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.0975, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:20<00:00,  7.14it/s, train:0.1296904981136322, test:2.4738852977752686]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:32:40.333677Z",
     "start_time": "2025-07-23T01:32:40.326975Z"
    }
   },
   "cell_type": "code",
   "source": "f_e.lin.weight, q_u[-1].m_u",
   "id": "9599b41b26199d55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.5433, -0.4727, -0.0763, -0.1268]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.8624]], requires_grad=True))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## V2",
   "id": "9696c717f8a84d5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:02:17.576990Z",
     "start_time": "2025-07-23T05:02:17.573729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "E = 1\n",
    "D = 0.1"
   ],
   "id": "81a04d1f40c074cf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Models",
   "id": "9da752a1eb6d9ba5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:38:19.844089Z",
     "start_time": "2025-07-23T05:38:19.835870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EBD(nn.Module):\n",
    "    def __init__(self, d_env):\n",
    "        super(EBD, self).__init__()\n",
    "        self.embedings = torch.nn.Embedding(d_env, 1).to(device)\n",
    "        self.re_init()\n",
    "\n",
    "    def re_init(self):\n",
    "        self.embedings.weight.data.fill_(1.)\n",
    "\n",
    "    def re_init_with_noise(self, d_env):\n",
    "        rd = torch.normal(\n",
    "            torch.Tensor([E] * d_env),\n",
    "            torch.Tensor([D] * d_env))\n",
    "        self.embedings.weight.data = rd.view(-1, 1).to(device)\n",
    "\n",
    "    def forward(self, e):\n",
    "        return self.embedings(e.long())\n",
    "\n",
    "class NeuralTest(nn.Module):\n",
    "    def __init__(self, dim = 5):\n",
    "        super(NeuralTest, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=4, out_features=12)\n",
    "        # self.fc1 = nn.Linear(in_features=2 + dim, out_features=4 + dim*2)\n",
    "        self.fc2 = nn.Linear(in_features=12, out_features=2 + dim//2)\n",
    "        self.drop = nn.Dropout(p = 0.2)\n",
    "        self.fc3 = nn.Linear(in_features=2 + dim//2, out_features=1)\n",
    "        self.selu = nn.SELU()\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.selu(self.fc1(z))\n",
    "        x = self.selu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        return self.fc3(x)\n",
    "\n",
    "class LinearTest(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(LinearTest, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=4, out_features=1)\n",
    "    def forward(self, z):\n",
    "        return self.fc1(z)"
   ],
   "id": "f5d819fe3e9fbd1f",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "3545bae393c6f868"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:41:55.796584Z",
     "start_time": "2025-07-23T05:41:55.782826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pe_train = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "pe_val = [0.4, 0.8]\n",
    "pe_test = [10, 100]\n",
    "n_samples = 1000\n",
    "\n",
    "train_env = [generate_dataset(pe, n_samples) for pe in pe_train]\n",
    "# train_env.append(combine_datasets(train_env))\n",
    "\n",
    "val_env = [generate_dataset(pe, n_samples) for pe in pe_val]\n",
    "X_val = torch.cat([x for x, _ in val_env], dim=0)\n",
    "Y_val = torch.cat([y for _, y in val_env], dim=0)\n",
    "val_env = [(X_val, Y_val)]\n",
    "\n",
    "test_env = [generate_dataset(pe, n_samples) for pe in pe_test]\n",
    "X_test = torch.cat([x for x, _ in test_env], dim=0)\n",
    "Y_test = torch.cat([y for _, y in test_env], dim=0)\n",
    "test_env = [(X_test, Y_test)]"
   ],
   "id": "ec87bef238e0e8d3",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:12:24.077426Z",
     "start_time": "2025-07-23T06:12:24.071579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_env = 5\n",
    "lamda = 100\n",
    "annealing_epochs = 1000\n",
    "ebd = EBD(d_env)\n",
    "model = LinearTest(d_env)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3)"
   ],
   "id": "663485f1b665faf8",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:12:24.374154Z",
     "start_time": "2025-07-23T06:12:24.368380Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_env)",
   "id": "b17f194c87b571cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:12:45.543865Z",
     "start_time": "2025-07-23T06:12:24.572441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in tqdm(range(5000)):\n",
    "    n_sample = 3\n",
    "    loss = 0\n",
    "    penalty = 0\n",
    "    for j in range(n_sample):\n",
    "        ebd.re_init_with_noise(d_env)\n",
    "        loss_list = []\n",
    "        for i_env, env in enumerate(train_env):\n",
    "            # X_train_e = torch.from_numpy(env[0].astype('float32')).to(device)\n",
    "            # Y_train_e = torch.from_numpy(env[1].astype('float32')).to(device)\n",
    "            X_train_e = env[0]\n",
    "            Y_train_e = env[1]\n",
    "            y_pred_e = model(X_train_e)\n",
    "            G_train_e = torch.ones_like(Y_train_e) * i_env\n",
    "            y_pred_e_w = y_pred_e * ebd(G_train_e).view(-1,1)\n",
    "            loss_e = criterion(y_pred_e_w, Y_train_e)\n",
    "        loss_list.append(loss_e)\n",
    "        loss_t = torch.stack(loss_list)\n",
    "        train_penalty0 = ((loss_t - loss_t.mean())**2).mean()\n",
    "        loss += loss_t.mean() / n_sample\n",
    "        penalty += train_penalty0 / n_sample\n",
    "    loss += penalty * (lamda if epoch > annealing_epochs else 0)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        val_mse = 0\n",
    "        for i_env, env in enumerate(val_env):\n",
    "            X_val = env[0]\n",
    "            Y_val = env[1]\n",
    "            y_pred = model(X_val)\n",
    "            val_mse += (y_pred - Y_val).pow(2).mean()\n",
    "        test_mse = 0\n",
    "        for i_env, env in enumerate(test_env):\n",
    "            X_test = env[0]\n",
    "            Y_test = env[1]\n",
    "            y_pred = model(X_test)\n",
    "            test_mse += (y_pred - Y_test).pow(2).mean()\n",
    "\n",
    "        print(f'train_loss: {loss:.4f}, penalty: {penalty}, val_mse:{val_mse:.4f}, test_mse: {test_mse:.4f}')\n",
    "print(model.fc1.weight)"
   ],
   "id": "1c8210e9a52221c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/5000 [00:00<00:21, 228.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.9508, penalty: 0.0, val_mse:2.7837, test_mse: 9.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 517/5000 [00:02<00:17, 256.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3639, penalty: 0.0, val_mse:0.2708, test_mse: 14.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1048/5000 [00:04<00:16, 241.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2167, penalty: 0.0, val_mse:0.1549, test_mse: 10.6605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1525/5000 [00:06<00:13, 250.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1492, penalty: 0.0, val_mse:0.1092, test_mse: 6.7428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2017/5000 [00:08<00:13, 226.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1553, penalty: 0.0, val_mse:0.0870, test_mse: 4.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2528/5000 [00:10<00:09, 254.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1276, penalty: 0.0, val_mse:0.0773, test_mse: 2.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3037/5000 [00:12<00:07, 246.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0887, penalty: 0.0, val_mse:0.0725, test_mse: 2.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3550/5000 [00:14<00:05, 255.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0824, penalty: 0.0, val_mse:0.0721, test_mse: 1.4774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4026/5000 [00:16<00:04, 209.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1269, penalty: 0.0, val_mse:0.0722, test_mse: 1.2258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4533/5000 [00:19<00:01, 248.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1068, penalty: 0.0, val_mse:0.0726, test_mse: 1.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 238.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.7930, 0.7981, 0.0860, 0.0900]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:46:12.355007Z",
     "start_time": "2025-07-23T04:46:12.083745Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b28d6e5f1ae71166",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m pe_test = [\u001B[32m10\u001B[39m, \u001B[32m100\u001B[39m]\n\u001B[32m      4\u001B[39m n_samples = \u001B[32m500\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m train_env = \u001B[43m[\u001B[49m\u001B[43mgenerate_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpe\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpe_train\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m      7\u001B[39m train_env.append(combine_datasets(train_env))\n\u001B[32m      8\u001B[39m val_env = [generate_dataset(pe, n_samples) \u001B[38;5;28;01mfor\u001B[39;00m pe \u001B[38;5;129;01min\u001B[39;00m pe_val]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m      3\u001B[39m pe_test = [\u001B[32m10\u001B[39m, \u001B[32m100\u001B[39m]\n\u001B[32m      4\u001B[39m n_samples = \u001B[32m500\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m train_env = [\u001B[43mgenerate_dataset\u001B[49m(pe, n_samples) \u001B[38;5;28;01mfor\u001B[39;00m pe \u001B[38;5;129;01min\u001B[39;00m pe_train]\n\u001B[32m      7\u001B[39m train_env.append(combine_datasets(train_env))\n\u001B[32m      8\u001B[39m val_env = [generate_dataset(pe, n_samples) \u001B[38;5;28;01mfor\u001B[39;00m pe \u001B[38;5;129;01min\u001B[39;00m pe_val]\n",
      "\u001B[31mNameError\u001B[39m: name 'generate_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad69625d463e0e65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
