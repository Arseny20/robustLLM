{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:03.869958Z",
     "start_time": "2025-07-23T01:07:00.724571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cpu'"
   ],
   "id": "7a862449f0a9bde9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "1abe3fef855424f8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:03.891949Z",
     "start_time": "2025-07-23T01:07:03.884151Z"
    }
   },
   "source": [
    "def generate_dataset(pe, n_samples):\n",
    "    # Invariant features ~ N(0, I)\n",
    "    X_inv = torch.randn(n_samples, 2)\n",
    "\n",
    "    # Label Y = x1 + x2 + noise\n",
    "    noise = torch.randn(n_samples) * (0.1 ** 0.5)\n",
    "    Y = X_inv.sum(dim=1) + noise  # Shape: (n_samples,)\n",
    "\n",
    "    # Spurious features ~ N([Y, Y], pe * I)\n",
    "    mean_spurious = torch.stack([Y, Y], dim=1)\n",
    "    spurious_noise = torch.randn(n_samples, 2) * (pe ** 0.5)\n",
    "    X_env = mean_spurious + spurious_noise\n",
    "\n",
    "    # Concatenate invariant and spurious features\n",
    "    X = torch.cat([X_inv, X_env], dim=1)\n",
    "    # Reshape labels to (n_samples, 1)\n",
    "    Y = Y.unsqueeze(1)\n",
    "    return X, Y\n",
    "\n",
    "def combine_datasets(datasets):\n",
    "    X = torch.concat([dataset[0] for dataset in datasets])\n",
    "    Y = torch.concat([dataset[1] for dataset in datasets])\n",
    "    return X, Y"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:04.017463Z",
     "start_time": "2025-07-23T01:07:03.913113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_1 = generate_dataset(0.5, 4)\n",
    "d_2 = generate_dataset(1.0, 4)\n",
    "d_3 = generate_dataset(9.9, 4)\n",
    "comb = combine_datasets([d_1, d_2, d_3])\n",
    "d_1"
   ],
   "id": "ea5f7fc879477966",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5295,  1.2863,  0.5123, -0.1659],\n",
       "         [-0.4916,  0.2065,  0.1590, -0.6059],\n",
       "         [-0.7471, -1.0425, -1.8465, -3.5519],\n",
       "         [-2.2299, -0.2309, -3.5473, -4.0008]]),\n",
       " tensor([[ 0.7578],\n",
       "         [ 0.0473],\n",
       "         [-2.0115],\n",
       "         [-2.6922]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Models",
   "id": "bd6a159600e679ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:52.512770Z",
     "start_time": "2025-07-23T01:07:52.507271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "out_features = 1"
   ],
   "id": "974959c63edac4b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:54.212089Z",
     "start_time": "2025-07-23T01:07:54.207313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.lin = nn.Linear(4,out_features,bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ],
   "id": "d9abefabab6b7a47",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:55.053663Z",
     "start_time": "2025-07-23T01:07:55.047525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, mean, std, epsilon) -> None:\n",
    "        super(Classifier, self).__init__()\n",
    "        self.w = mean + std*epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.w.T)"
   ],
   "id": "c182823ab626aa39",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:07:56.130477Z",
     "start_time": "2025-07-23T01:07:56.120286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.m_u = torch.nn.parameter.Parameter(torch.rand(1,out_features))\n",
    "        self.std = torch.nn.parameter.Parameter(torch.rand(1,out_features))\n",
    "        torch.nn.init.uniform_(self.m_u, -1, 1)\n",
    "        torch.nn.init.uniform_(self.std, 0, 1)\n",
    "\n",
    "    def recon_loss(self, X, Y, classifier, f_e): #minimize this\n",
    "        return F.mse_loss(Y, classifier(f_e(X)))\n",
    "\n",
    "    def KL_loss(self):   #maximize this\n",
    "        return torch.sum(1 + torch.log(torch.square(self.std)) - torch.square(self.m_u) - torch.square(self.std))/2\n",
    "\n",
    "    def sample(self, epsilon=None):\n",
    "        if epsilon is None:\n",
    "            epsilon =  torch.randn_like(self.m_u).to(device)\n",
    "        return Classifier(self.m_u, self.std, epsilon)\n",
    "\n",
    "    def fit(self, X, Y, f_e, epochs):\n",
    "        optim = torch.optim.Adam([self.m_u, self.std], betas=(0.5, 0.5))\n",
    "        for _ in range(epochs):\n",
    "            loss = self.recon_loss(X, Y, self.sample(), f_e) - self.KL_loss()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()"
   ],
   "id": "f2e73c94b641bda1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "a157484f1945ac18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:27:36.134085Z",
     "start_time": "2025-07-23T01:27:36.125009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pe_train = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "pe_val = [0.4, 0.8]\n",
    "pe_test = [10, 100]\n",
    "n_samples = 500\n",
    "\n",
    "train_env = [generate_dataset(pe, n_samples) for pe in pe_train]\n",
    "train_env.append(combine_datasets(train_env))\n",
    "val_env = [generate_dataset(pe, n_samples) for pe in pe_val]\n",
    "X_val = torch.cat([x for x, _ in val_env], dim=0)\n",
    "Y_val = torch.cat([y for _, y in val_env], dim=0)\n",
    "val_env = [(X_val, Y_val)]\n",
    "test_env = [generate_dataset(pe, n_samples) for pe in pe_test]\n",
    "X_test = torch.cat([x for x, _ in test_env], dim=0)\n",
    "Y_test = torch.cat([y for _, y in test_env], dim=0)\n",
    "test_env = [(X_test, Y_test)]"
   ],
   "id": "ca7620111ed032a8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:27:41.473659Z",
     "start_time": "2025-07-23T01:27:41.471273Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "526b410090d66954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:40:47.254815Z",
     "start_time": "2025-07-23T01:38:27.085253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f_e = FeatureExtractor().to(device)\n",
    "q_u = [AutoEncoder().to(device) for _ in train_env]\n",
    "\n",
    "lamda = 5\n",
    "with tqdm(range(1000)) as tepoch:\n",
    "    for ep in tepoch:\n",
    "        # Update posteriors distribution of classifiers for each training environment\n",
    "        for q, D in zip(q_u, train_env):\n",
    "            q.fit(D[0], D[1], f_e, 20)\n",
    "\n",
    "        # Update feature extractor only\n",
    "        loss = 0\n",
    "        optim = torch.optim.Adam(f_e.parameters(), betas=(0.5, 0.5), lr=0.01)\n",
    "        for _ in range(10):\n",
    "            epsilon = torch.randn_like(q_u[-1].m_u).to(device)\n",
    "            [ loss := loss + (1+lamda)*q_u[-1].recon_loss(D[0], D[1], q_u[-1].sample(epsilon), f_e)-lamda*q.recon_loss(D[0], D[1], q.sample(epsilon), f_e)  for q, D in zip(q_u[:-1], train_env[:-1]) ]\n",
    "        loss = loss/10\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epsilon = torch.zeros_like(q_u[-1].m_u).to(device)\n",
    "        test_acc = q_u[-1].recon_loss(test_env[0][0], test_env[0][1], q_u[-1].sample(epsilon), f_e)\n",
    "        train_acc = q_u[-1].recon_loss(train_env[-1][0], train_env[-1][1], q_u[-1].sample(epsilon), f_e)\n",
    "        tepoch.set_postfix_str(f'train:{train_acc}, test:{test_acc}')\n",
    "\n",
    "        if ep%50==0:\n",
    "            print(torch.matmul(q_u[-1].m_u, f_e.lin.weight))\n",
    "            print(f_e.lin.weight)"
   ],
   "id": "8df30a13c66419ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<02:40,  6.22it/s, train:2.7753427028656006, test:3.357396125793457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1106,  0.0435, -0.0517, -0.0903]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.4330,  0.1702, -0.2025, -0.3537]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:07<02:16,  6.96it/s, train:1.4322160482406616, test:1.6862764358520508]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0146, 0.1525, 0.0614, 0.0144]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.0470, 0.4902, 0.1975, 0.0463]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:14<02:01,  7.39it/s, train:0.6221087574958801, test:1.4772703647613525]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2831, 0.3205, 0.1191, 0.0747]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.3270, 0.3702, 0.1375, 0.0863]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [00:20<02:02,  6.90it/s, train:0.3509792387485504, test:1.5431060791015625] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4109, 0.4140, 0.1131, 0.1216]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4270, 0.4302, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [00:28<01:50,  7.25it/s, train:0.2563991844654083, test:2.046274185180664]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4381, 0.4411, 0.1290, 0.1560]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4670, 0.4702, 0.1375, 0.1663]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:34<01:40,  7.46it/s, train:0.1273856908082962, test:3.2789905071258545] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4605, 0.4816, 0.1612, 0.1692]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5070, 0.5302, 0.1775, 0.1863]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [00:41<01:48,  6.47it/s, train:0.3417434096336365, test:1.2421739101409912] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4472, 0.4502, 0.0896, 0.1160]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4870, 0.4902, 0.0975, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 352/1000 [00:48<01:31,  7.12it/s, train:0.34626781940460205, test:1.2922898530960083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4446, 0.4477, 0.0929, 0.1203]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4670, 0.4702, 0.0975, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [00:55<01:23,  7.16it/s, train:0.15628857910633087, test:2.424215316772461] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4845, 0.4875, 0.1265, 0.1529]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.1375, 0.1663]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [01:03<01:16,  7.13it/s, train:0.2671554386615753, test:1.5219216346740723] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4417, 0.4627, 0.0885, 0.1146]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4870, 0.5102, 0.0975, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:10<01:11,  7.01it/s, train:0.17667031288146973, test:2.308046817779541] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4682, 0.4711, 0.1222, 0.1478]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.1375, 0.1663]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 552/1000 [01:18<01:01,  7.23it/s, train:0.18404708802700043, test:2.0895962715148926]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4972, 0.4999, 0.1334, 0.1578]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5870, 0.5902, 0.1575, 0.1863]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 602/1000 [01:24<00:52,  7.55it/s, train:0.36993879079818726, test:1.1244726181030273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4264, 0.4291, 0.0652, 0.0894]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5070, 0.5102, 0.0775, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [01:31<00:47,  7.33it/s, train:0.19690154492855072, test:1.7407044172286987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4933, 0.4964, 0.1100, 0.1183]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 702/1000 [01:38<00:42,  7.03it/s, train:0.24483706057071686, test:1.6063544750213623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4801, 0.4830, 0.1207, 0.1284]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5470, 0.5502, 0.1375, 0.1463]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 752/1000 [01:45<00:34,  7.23it/s, train:0.21476979553699493, test:1.5810916423797607]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4784, 0.4987, 0.1028, 0.1105]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5470, 0.5702, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 802/1000 [01:52<00:26,  7.60it/s, train:0.3476116359233856, test:0.953772783279419]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4785, 0.4812, 0.0823, 0.0897]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5670, 0.5702, 0.0975, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [01:58<00:20,  7.05it/s, train:0.1763838529586792, test:1.5947726964950562] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5211, 0.5240, 0.1043, 0.1122]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5870, 0.5902, 0.1175, 0.1263]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [02:05<00:13,  7.23it/s, train:0.25676387548446655, test:1.0496997833251953]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5283, 0.5314, 0.0942, 0.1027]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5470, 0.5502, 0.0975, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [02:13<00:07,  6.76it/s, train:0.22807025909423828, test:1.3618232011795044]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4993, 0.5024, 0.0924, 0.1007]], grad_fn=<MmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.5270, 0.5302, 0.0975, 0.1063]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:20<00:00,  7.14it/s, train:0.1296904981136322, test:2.4738852977752686]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T01:32:40.333677Z",
     "start_time": "2025-07-23T01:32:40.326975Z"
    }
   },
   "cell_type": "code",
   "source": "f_e.lin.weight, q_u[-1].m_u",
   "id": "9599b41b26199d55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.5433, -0.4727, -0.0763, -0.1268]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.8624]], requires_grad=True))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5d819fe3e9fbd1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
