{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T12:41:57.654464Z",
     "start_time": "2025-07-22T12:41:54.234431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import grad"
   ],
   "id": "7b89087b55e36500",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d84ba657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T12:42:04.142739Z",
     "start_time": "2025-07-22T12:42:04.133193Z"
    }
   },
   "source": [
    "def generate_environment_df(n_samples, pe, env_id):\n",
    "    # ГЕНЕРАЦИЯ ДАННЫХ\n",
    "    I2 = np.eye(2)\n",
    "\n",
    "    # Invariant features ~ N(0, I)\n",
    "    X_inv = np.random.multivariate_normal(mean=[0, 0], cov=I2, size=n_samples)\n",
    "\n",
    "    # Label Y = x1 + x2 + noise\n",
    "    Y = X_inv.sum(axis=1) + np.random.normal(loc=0.0, scale=np.sqrt(0.1), size=n_samples)\n",
    "\n",
    "    # Spurious features ~ N([Y, Y], pe * I)\n",
    "    X_env = np.stack([Y, Y], axis=1) + np.random.multivariate_normal(mean=[0, 0], cov=pe * I2, size=n_samples)\n",
    "\n",
    "    # Combine into DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"x_inv_0\": X_inv[:, 0],\n",
    "        \"x_inv_1\": X_inv[:, 1],\n",
    "        \"x_env_0\": X_env[:, 0],\n",
    "        \"x_env_1\": X_env[:, 1],\n",
    "        \"y\": Y,\n",
    "        \"env_id\": env_id,\n",
    "        \"pe\": pe\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_irm_dataset(n_samples_per_env=10000):\n",
    "    pe_train = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    pe_val = [0.4, 0.8]\n",
    "    pe_test = [10, 100]\n",
    "\n",
    "    # Build full DataFrames for each split\n",
    "    train_df = pd.concat(\n",
    "        [generate_environment_df(n_samples_per_env, pe, f\"train_{i}\") for i, pe in enumerate(pe_train)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    val_df = pd.concat(\n",
    "        [generate_environment_df(n_samples_per_env, pe, f\"val_{i}\") for i, pe in enumerate(pe_val)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    test_df = pd.concat(\n",
    "        [generate_environment_df(n_samples_per_env, pe, f\"test_{i}\") for i, pe in enumerate(pe_test)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    return train_df, val_df, test_df"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6f37b93c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T12:48:05.730025Z",
     "start_time": "2025-07-22T12:48:05.687423Z"
    }
   },
   "source": [
    "train_data, val_data, test_data = generate_irm_dataset()\n",
    "train_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        x_inv_0   x_inv_1   x_env_0   x_env_1         y   env_id   pe\n",
       "0     -1.469810 -0.830495 -2.325618 -2.549137 -2.172993  train_0  0.1\n",
       "1      1.466444 -0.645346  1.376228  1.866707  1.481395  train_0  0.1\n",
       "2      0.290827 -1.342223 -1.045797 -1.383820 -1.086729  train_0  0.1\n",
       "3      0.523213 -0.440730  0.174339  0.100720  0.306921  train_0  0.1\n",
       "4      0.164199 -0.543173  0.202890 -0.271840 -0.290782  train_0  0.1\n",
       "...         ...       ...       ...       ...       ...      ...  ...\n",
       "49995  1.129743 -0.536946  0.892962  0.891121  0.557372  train_4  0.9\n",
       "49996 -0.734538 -0.345828 -0.839470 -0.792336 -0.728310  train_4  0.9\n",
       "49997  0.675012 -0.385911  0.814162 -0.424337  0.131894  train_4  0.9\n",
       "49998  0.208335 -0.226202 -1.258210 -0.480109  0.056446  train_4  0.9\n",
       "49999  2.525337 -0.647026  1.098715  2.007891  2.265695  train_4  0.9\n",
       "\n",
       "[50000 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_inv_0</th>\n",
       "      <th>x_inv_1</th>\n",
       "      <th>x_env_0</th>\n",
       "      <th>x_env_1</th>\n",
       "      <th>y</th>\n",
       "      <th>env_id</th>\n",
       "      <th>pe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.469810</td>\n",
       "      <td>-0.830495</td>\n",
       "      <td>-2.325618</td>\n",
       "      <td>-2.549137</td>\n",
       "      <td>-2.172993</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.466444</td>\n",
       "      <td>-0.645346</td>\n",
       "      <td>1.376228</td>\n",
       "      <td>1.866707</td>\n",
       "      <td>1.481395</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.290827</td>\n",
       "      <td>-1.342223</td>\n",
       "      <td>-1.045797</td>\n",
       "      <td>-1.383820</td>\n",
       "      <td>-1.086729</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523213</td>\n",
       "      <td>-0.440730</td>\n",
       "      <td>0.174339</td>\n",
       "      <td>0.100720</td>\n",
       "      <td>0.306921</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164199</td>\n",
       "      <td>-0.543173</td>\n",
       "      <td>0.202890</td>\n",
       "      <td>-0.271840</td>\n",
       "      <td>-0.290782</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1.129743</td>\n",
       "      <td>-0.536946</td>\n",
       "      <td>0.892962</td>\n",
       "      <td>0.891121</td>\n",
       "      <td>0.557372</td>\n",
       "      <td>train_4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>-0.734538</td>\n",
       "      <td>-0.345828</td>\n",
       "      <td>-0.839470</td>\n",
       "      <td>-0.792336</td>\n",
       "      <td>-0.728310</td>\n",
       "      <td>train_4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.675012</td>\n",
       "      <td>-0.385911</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>-0.424337</td>\n",
       "      <td>0.131894</td>\n",
       "      <td>train_4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.208335</td>\n",
       "      <td>-0.226202</td>\n",
       "      <td>-1.258210</td>\n",
       "      <td>-0.480109</td>\n",
       "      <td>0.056446</td>\n",
       "      <td>train_4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>2.525337</td>\n",
       "      <td>-0.647026</td>\n",
       "      <td>1.098715</td>\n",
       "      <td>2.007891</td>\n",
       "      <td>2.265695</td>\n",
       "      <td>train_4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ec892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "torch.Size([10000, 4]) torch.Size([10000, 4]) torch.Size([10000, 4])\n",
      "Iteration 0, Training Loss: 0.006103, Validation MSE: 2.185445\n",
      "Iteration 500, Training Loss: 0.003209, Validation MSE: 0.985494\n",
      "Iteration 1000, Training Loss: 0.001733, Validation MSE: 0.495343\n",
      "Iteration 1500, Training Loss: 0.000981, Validation MSE: 0.263894\n",
      "Iteration 2000, Training Loss: 0.000743, Validation MSE: 0.197901\n",
      "Iteration 2500, Training Loss: 0.000688, Validation MSE: 0.185176\n",
      "IRM (reg=1.000e-03) has 0.091965 validation error.\n",
      "\n",
      "Best reg=1.000e-03 with validation error=0.183896\n",
      "torch.Size([10000, 4])\n",
      "torch.Size([10000, 4])\n",
      "\n",
      "Validation MSE: 0.183896\n",
      "Test MSE: 0.403704\n",
      "Validation/Test Ratio: 2.195287\n",
      "tensor([[0.9626],\n",
      "        [0.9259],\n",
      "        [0.0429],\n",
      "        [0.0142]], device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def detect_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "def to_torch(df, device):\n",
    "    X = torch.tensor(df[[\"x_inv_0\", \"x_inv_1\", \"x_env_0\", \"x_env_1\"]].values, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(df[\"y\"].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "    env_ids = df[\"env_id\"].unique()\n",
    "    environments = []\n",
    "    for env in env_ids:\n",
    "        mask = df[\"env_id\"] == env\n",
    "        environments.append((X[mask], y[mask]))\n",
    "    return environments\n",
    "\n",
    "def initialize_model(dim_x, device):\n",
    "    phi = torch.nn.Parameter(torch.eye(dim_x,1, device=device))\n",
    "    dummy_w = torch.ones(1, 1, device=device, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([phi], lr=1e-3)\n",
    "    return phi, dummy_w, optimizer\n",
    "\n",
    "def compute_penalty(error, dummy_w):\n",
    "    grad_w = grad(error, dummy_w, create_graph=True)[0]\n",
    "    penalty = grad_w.pow(2).mean()\n",
    "    return penalty\n",
    "\n",
    "def train_model(train_envs,val_envs, phi, dummy_w, optimizer, reg=1e-3, iterations=500, verbose=True):\n",
    "    mse = torch.nn.MSELoss()\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        total_error = 0\n",
    "        total_penalty = 0\n",
    "        \n",
    "        for x_e, y_e in train_envs:\n",
    "            error_e = mse((x_e @ phi) @ dummy_w, y_e)\n",
    "            penalty_e = compute_penalty(error_e, dummy_w)\n",
    "            total_error += error_e\n",
    "            total_penalty += penalty_e\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = reg * total_error + (1 - reg) * total_penalty\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and iteration % 100 == 0:\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for x_e, y_e in val_envs:\n",
    "                    error_val = mse((x_e @ phi) @ dummy_w, y_e)\n",
    "                    total_val += error_val\n",
    "                print(f\"Iteration {iteration}, Training Loss: {loss.item():.6f}, Validation MSE: {total_val:.6f}\")\n",
    "\n",
    "def tune_regularization(train_envs, val_envs, dim_x, device, reg_values, iterations=100, verbose=True):\n",
    "    best_err = float('inf')\n",
    "    best_reg = None\n",
    "    best_phi = None\n",
    "    mse = torch.nn.MSELoss()\n",
    "    for reg in reg_values:\n",
    "        phi, dummy_w, optimizer = initialize_model(dim_x, device)\n",
    "        train_model(train_envs,val_envs,  phi, dummy_w, optimizer, reg=reg, iterations=iterations, verbose=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "           total_val = 0\n",
    "           for x_e, y_e in val_envs:\n",
    "                    error_val = mse((x_e @ phi) @ dummy_w, y_e)\n",
    "                    total_val += error_val\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"IRM (reg={reg:.3e}) has {error_val:.6f} validation error.\")\n",
    "        \n",
    "        if total_val < best_err:\n",
    "            best_err = total_val\n",
    "            best_reg = reg\n",
    "            best_phi = phi.clone()\n",
    "\n",
    "    print(f\"\\nBest reg={best_reg:.3e} with validation error={total_val:.6f}\")\n",
    "    return best_phi, best_reg\n",
    "\n",
    "def evaluate_model(phi, dummy_w, test_envs, val_envs):\n",
    "    total_test = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        mse = torch.nn.MSELoss()\n",
    "        for t, v in zip(test_envs,val_envs):\n",
    "            error_test = mse((t[0] @ phi) @ dummy_w, t[1])\n",
    "            error_val = mse((v[0] @ phi) @ dummy_w, v[1])\n",
    "            total_test += error_test\n",
    "            total_val += error_val\n",
    "        ratio = total_test / total_val\n",
    "    print(f\"\\nValidation MSE: {total_val:.6f}\")\n",
    "    print(f\"Test MSE: {total_test:.6f}\")\n",
    "    print(f\"Validation/Test Ratio: {ratio:.6f}\")\n",
    "\n",
    "def main():\n",
    "    device = detect_device()\n",
    "    \n",
    "    # Load datasets\n",
    "    train_envs = to_torch(train_data, device)\n",
    "    val_envs = to_torch(val_data, device)\n",
    "    test_envs= to_torch(test_data, device)\n",
    "    dim_x = train_envs[0][0].shape[1]\n",
    "    reg_values = [1e-3]\n",
    "    \n",
    "    best_phi, best_reg = tune_regularization(train_envs,val_envs, dim_x, device, reg_values, iterations=3000)\n",
    "    \n",
    "    dummy_w = torch.ones(1, 1, device=device)\n",
    "    evaluate_model(best_phi, dummy_w, test_envs, val_envs)\n",
    "    print(best_phi)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628eb4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
