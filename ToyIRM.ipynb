{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84ba657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "def generate_environment_df(n_samples, pe, env_id):\n",
    "#ГЕНЕРАЦИЯ ДАННЫХ\n",
    "    I2 = np.eye(2)\n",
    "\n",
    "    # Invariant features ~ N(0, I)\n",
    "    X_inv = np.random.multivariate_normal(mean=[0, 0], cov=I2, size=n_samples)\n",
    "\n",
    "    # Label Y = x1 + x2 + noise\n",
    "    Y = X_inv.sum(axis=1) + np.random.normal(loc=0.0, scale=np.sqrt(0.1), size=n_samples)\n",
    "\n",
    "    # Spurious features ~ N([Y, Y], pe * I)\n",
    "    X_env = np.stack([Y, Y], axis=1) + np.random.multivariate_normal(mean=[0, 0], cov=pe * I2, size=n_samples)\n",
    "\n",
    "    # Combine into DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"x_inv_0\": X_inv[:, 0],\n",
    "        \"x_inv_1\": X_inv[:, 1],\n",
    "        \"x_env_0\": X_env[:, 0],\n",
    "        \"x_env_1\": X_env[:, 1],\n",
    "        \"y\": Y,\n",
    "        \"env_id\": env_id,\n",
    "        \"pe\": pe\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_irm_dataset(n_samples_per_env=10000):\n",
    "    pe_train = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    pe_val = [0.4, 0.8]\n",
    "    pe_test = [10, 100]\n",
    "\n",
    "    # Build full DataFrames for each split\n",
    "    train_df = pd.concat(\n",
    "        [generate_environment_df(n_samples_per_env, pe, f\"train_{i}\") for i, pe in enumerate(pe_train)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    val_df = pd.concat(\n",
    "        [generate_environment_df(n_samples_per_env, pe, f\"val_{i}\") for i, pe in enumerate(pe_val)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    test_df = pd.concat(\n",
    "        [generate_environment_df(n_samples_per_env, pe, f\"test_{i}\") for i, pe in enumerate(pe_test)],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f37b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = generate_irm_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ec892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "torch.Size([10000, 4]) torch.Size([10000, 4]) torch.Size([10000, 4])\n",
      "Iteration 0, Training Loss: 0.006103, Validation MSE: 2.185445\n",
      "Iteration 500, Training Loss: 0.003209, Validation MSE: 0.985494\n",
      "Iteration 1000, Training Loss: 0.001733, Validation MSE: 0.495343\n",
      "Iteration 1500, Training Loss: 0.000981, Validation MSE: 0.263894\n",
      "Iteration 2000, Training Loss: 0.000743, Validation MSE: 0.197901\n",
      "Iteration 2500, Training Loss: 0.000688, Validation MSE: 0.185176\n",
      "IRM (reg=1.000e-03) has 0.091965 validation error.\n",
      "\n",
      "Best reg=1.000e-03 with validation error=0.183896\n",
      "torch.Size([10000, 4])\n",
      "torch.Size([10000, 4])\n",
      "\n",
      "Validation MSE: 0.183896\n",
      "Test MSE: 0.403704\n",
      "Validation/Test Ratio: 2.195287\n",
      "tensor([[0.9626],\n",
      "        [0.9259],\n",
      "        [0.0429],\n",
      "        [0.0142]], device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "\n",
    "def detect_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "def to_torch(df, device):\n",
    "    X = torch.tensor(df[[\"x_inv_0\", \"x_inv_1\", \"x_env_0\", \"x_env_1\"]].values, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(df[\"y\"].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "    env_ids = df[\"env_id\"].unique()\n",
    "    environments = []\n",
    "    for env in env_ids:\n",
    "        mask = df[\"env_id\"] == env\n",
    "        environments.append((X[mask], y[mask]))\n",
    "    return environments\n",
    "\n",
    "def initialize_model(dim_x, device):\n",
    "    phi = torch.nn.Parameter(torch.eye(dim_x,1, device=device))\n",
    "    dummy_w = torch.ones(1, 1, device=device, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([phi], lr=1e-3)\n",
    "    return phi, dummy_w, optimizer\n",
    "\n",
    "def compute_penalty(error, dummy_w):\n",
    "    grad_w = grad(error, dummy_w, create_graph=True)[0]\n",
    "    penalty = grad_w.pow(2).mean()\n",
    "    return penalty\n",
    "\n",
    "def train_model(train_envs,val_envs, phi, dummy_w, optimizer, reg=1e-3, iterations=500, verbose=True):\n",
    "    mse = torch.nn.MSELoss()\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        total_error = 0\n",
    "        total_penalty = 0\n",
    "        \n",
    "        for x_e, y_e in train_envs:\n",
    "            error_e = mse((x_e @ phi) @ dummy_w, y_e)\n",
    "            penalty_e = compute_penalty(error_e, dummy_w)\n",
    "            total_error += error_e\n",
    "            total_penalty += penalty_e\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = reg * total_error + (1 - reg) * total_penalty\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and iteration % 100 == 0:\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for x_e, y_e in val_envs:\n",
    "                    error_val = mse((x_e @ phi) @ dummy_w, y_e)\n",
    "                    total_val += error_val\n",
    "                print(f\"Iteration {iteration}, Training Loss: {loss.item():.6f}, Validation MSE: {total_val:.6f}\")\n",
    "\n",
    "def tune_regularization(train_envs, val_envs, dim_x, device, reg_values, iterations=100, verbose=True):\n",
    "    best_err = float('inf')\n",
    "    best_reg = None\n",
    "    best_phi = None\n",
    "    mse = torch.nn.MSELoss()\n",
    "    for reg in reg_values:\n",
    "        phi, dummy_w, optimizer = initialize_model(dim_x, device)\n",
    "        train_model(train_envs,val_envs,  phi, dummy_w, optimizer, reg=reg, iterations=iterations, verbose=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "           total_val = 0\n",
    "           for x_e, y_e in val_envs:\n",
    "                    error_val = mse((x_e @ phi) @ dummy_w, y_e)\n",
    "                    total_val += error_val\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"IRM (reg={reg:.3e}) has {error_val:.6f} validation error.\")\n",
    "        \n",
    "        if total_val < best_err:\n",
    "            best_err = total_val\n",
    "            best_reg = reg\n",
    "            best_phi = phi.clone()\n",
    "\n",
    "    print(f\"\\nBest reg={best_reg:.3e} with validation error={total_val:.6f}\")\n",
    "    return best_phi, best_reg\n",
    "\n",
    "def evaluate_model(phi, dummy_w, test_envs, val_envs):\n",
    "    total_test = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        mse = torch.nn.MSELoss()\n",
    "        for t, v in zip(test_envs,val_envs):\n",
    "            error_test = mse((t[0] @ phi) @ dummy_w, t[1])\n",
    "            error_val = mse((v[0] @ phi) @ dummy_w, v[1])\n",
    "            total_test += error_test\n",
    "            total_val += error_val\n",
    "        ratio = total_test / total_val\n",
    "    print(f\"\\nValidation MSE: {total_val:.6f}\")\n",
    "    print(f\"Test MSE: {total_test:.6f}\")\n",
    "    print(f\"Validation/Test Ratio: {ratio:.6f}\")\n",
    "\n",
    "def main():\n",
    "    device = detect_device()\n",
    "    \n",
    "    # Load datasets\n",
    "    train_envs = to_torch(train_data, device)\n",
    "    val_envs = to_torch(val_data, device)\n",
    "    test_envs= to_torch(test_data, device)\n",
    "    dim_x = train_envs[0][0].shape[1]\n",
    "    reg_values = [1e-3]\n",
    "    \n",
    "    best_phi, best_reg = tune_regularization(train_envs,val_envs, dim_x, device, reg_values, iterations=3000)\n",
    "    \n",
    "    dummy_w = torch.ones(1, 1, device=device)\n",
    "    evaluate_model(best_phi, dummy_w, test_envs, val_envs)\n",
    "    print(best_phi)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628eb4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
