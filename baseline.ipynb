{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada37b98",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99355324-887a-46c3-816a-5911aff6cae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T11:16:21.509934Z",
     "iopub.status.busy": "2025-07-23T11:16:21.509527Z",
     "iopub.status.idle": "2025-07-23T11:16:21.534250Z",
     "shell.execute_reply": "2025-07-23T11:16:21.533450Z",
     "shell.execute_reply.started": "2025-07-23T11:16:21.509913Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452b2954-6fa4-467b-b2b7-0493bcd60031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8918e11-de7d-45ba-9b1a-321bc467f8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:36:29.313267Z",
     "iopub.status.busy": "2025-07-23T12:36:29.312829Z",
     "iopub.status.idle": "2025-07-23T12:36:40.466790Z",
     "shell.execute_reply": "2025-07-23T12:36:40.465853Z",
     "shell.execute_reply.started": "2025-07-23T12:36:29.313245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/xlm-roberta-large-en-ru\")\n",
    "base_model = AutoModel.from_pretrained(\"DeepPavlov/xlm-roberta-large-en-ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495a07b9-78b5-4f61-823a-d359224813a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T11:16:19.946320Z",
     "iopub.status.busy": "2025-07-23T11:16:19.945196Z",
     "iopub.status.idle": "2025-07-23T11:16:21.508082Z",
     "shell.execute_reply": "2025-07-23T11:16:21.506951Z",
     "shell.execute_reply.started": "2025-07-23T11:16:19.946290Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Open and load JSON file\n",
    "with open('D:\\\\project_IRM\\\\robustLLM\\\\samples_8.json', 'r', encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b5fd78-e52e-42fa-b28a-d2115f8bc2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T11:33:52.233367Z",
     "iopub.status.busy": "2025-07-23T11:33:52.232908Z",
     "iopub.status.idle": "2025-07-23T11:33:52.248868Z",
     "shell.execute_reply": "2025-07-23T11:33:52.248176Z",
     "shell.execute_reply.started": "2025-07-23T11:33:52.233345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = ['address', 'email', 'fio', 'ip', 'ipv6', 'login', 'org', 'password', 'phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ec2f2dc-d73c-4560-a5d7-8038edcf7c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:31:35.435863Z",
     "iopub.status.busy": "2025-07-23T12:31:35.435337Z",
     "iopub.status.idle": "2025-07-23T12:31:35.467658Z",
     "shell.execute_reply": "2025-07-23T12:31:35.466819Z",
     "shell.execute_reply.started": "2025-07-23T12:31:35.435841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import chain\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "def sample_and_split_diverse(\n",
    "    data: Dict[Any, Dict[Any, Dict[Any, Dict[Any, List[Dict]]]]],\n",
    "    n_samples: int,\n",
    "    val_ratio: float,\n",
    "    seed: int = None\n",
    ") -> Tuple[Tuple[List[str], List[Dict]], Tuple[List[str], List[Dict]]]:\n",
    "    \"\"\"\n",
    "    Perform stratified sampling across (log_env, length) groups so that\n",
    "    both train and val contain entries from each group.\n",
    "\n",
    "    Args:\n",
    "        data: nested dict of shape\n",
    "              data[log_env][length][template][lang] -> list of {text, spans}\n",
    "        n_samples: total number of examples (train + val)\n",
    "        val_ratio: fraction of examples for validation\n",
    "        seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        ((train_texts, train_spans), (val_texts, val_spans))\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 1. Flatten into groups\n",
    "    groups: List[Tuple[Tuple[Any, Any], List[Dict]]] = []\n",
    "    for log_env_val, lengths in data.items():\n",
    "        for length_val, templates in lengths.items():\n",
    "            entries = []\n",
    "            for tmpl in templates.values():\n",
    "                for lang_list in tmpl.values():\n",
    "                    entries.extend(lang_list)\n",
    "            if entries:\n",
    "                groups.append(((log_env_val, length_val), entries))\n",
    "\n",
    "    # Compute total available entries\n",
    "    total_entries = sum(len(entries) for _, entries in groups)\n",
    "    print('total_entries:', total_entries)\n",
    "    if total_entries < n_samples:\n",
    "        raise ValueError(f\"Not enough total examples: {total_entries} < {n_samples}\")\n",
    "\n",
    "    n_val = int(n_samples * val_ratio)\n",
    "    n_train = n_samples - n_val\n",
    "\n",
    "    train_samples: List[Dict] = []\n",
    "    val_samples:   List[Dict] = []\n",
    "\n",
    "    # 2. For each group, allocate proportional samples then split\n",
    "    acc_train, acc_val = 0, 0\n",
    "    for (env_len, entries) in groups:\n",
    "        group_size = len(entries)\n",
    "        # number of samples to take from this group\n",
    "        group_n = max(1, int(group_size / total_entries * n_samples))\n",
    "        # adjust last group to exactly fill\n",
    "        if acc_train + acc_val + group_n > n_samples:\n",
    "            group_n = n_samples - (acc_train + acc_val)\n",
    "\n",
    "        # number of val samples from this group\n",
    "        group_val_n = int(group_n * val_ratio)\n",
    "        group_train_n = group_n - group_val_n\n",
    "\n",
    "        # sample without replacement\n",
    "        sampled = random.sample(entries, group_n)\n",
    "        val_subset   = sampled[:group_val_n]\n",
    "        train_subset = sampled[group_val_n:]\n",
    "\n",
    "        val_samples.extend(val_subset)\n",
    "        train_samples.extend(train_subset)\n",
    "        acc_val   += len(val_subset)\n",
    "        acc_train += len(train_subset)\n",
    "\n",
    "    # 3. If rounding left us short, fill remaining slots from the pools\n",
    "    def fill(samples: List[Dict], pool: List[Dict], need: int):\n",
    "        if need <= 0:\n",
    "            return\n",
    "        remaining = [e for e in pool if e not in samples]\n",
    "        samples.extend(random.sample(remaining, need))\n",
    "\n",
    "    fill(val_samples,   list(chain.from_iterable(g for _, g in groups)), n_val - len(val_samples))\n",
    "    fill(train_samples, list(chain.from_iterable(g for _, g in groups)), n_train - len(train_samples))\n",
    "\n",
    "    # 4. Unpack texts and spans\n",
    "    train_texts = [e['text'] for e in train_samples]\n",
    "    train_spans = [e['spans'] for e in train_samples]\n",
    "    val_texts   = [e['text'] for e in val_samples]\n",
    "    val_spans   = [e['spans'] for e in val_samples]\n",
    "\n",
    "    return ( (train_texts, train_spans), (val_texts, val_spans) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69595599-8a2c-43c4-a604-9e5e44d99d34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:31:36.275236Z",
     "iopub.status.busy": "2025-07-23T12:31:36.274875Z",
     "iopub.status.idle": "2025-07-23T12:31:48.535859Z",
     "shell.execute_reply": "2025-07-23T12:31:48.534838Z",
     "shell.execute_reply.started": "2025-07-23T12:31:36.275216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_entries: 167600\n"
     ]
    }
   ],
   "source": [
    "(data_train, ner_train), (data_val, ner_val) = sample_and_split_diverse(data, 10, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087185be-bb45-464b-b5ad-8f388a8f9b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:31:48.537547Z",
     "iopub.status.busy": "2025-07-23T12:31:48.537142Z",
     "iopub.status.idle": "2025-07-23T12:31:48.557005Z",
     "shell.execute_reply": "2025-07-23T12:31:48.556192Z",
     "shell.execute_reply.started": "2025-07-23T12:31:48.537526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_train), \u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m14\u001b[39;49m\u001b[43m]\u001b[49m, ner_train[\u001b[32m14\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "len(data_train), data_train[14], ner_train[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b845da4e-416b-438f-8714-14d37ba14cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:31:48.558321Z",
     "iopub.status.busy": "2025-07-23T12:31:48.557792Z",
     "iopub.status.idle": "2025-07-23T12:31:48.614037Z",
     "shell.execute_reply": "2025-07-23T12:31:48.613221Z",
     "shell.execute_reply.started": "2025-07-23T12:31:48.558300Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_log = ['80.97.168.58 - gorshkovnikon [Тимофеев Серафим Антонович] (email: viktor15@example.net, pass: _7Ys%IVQp2) phone=8 826 587 31 88 addr=\"к. Армавир, наб. Грибоедова, д. 9/3 стр. 5/3, 937143\" org=Медведева и партнеры ipv6=64be:ec33:33f1:1207:5d95:7f1:8710:a5','A support ticket was created by user jeffrey97 from organization Hill-Hall. The ticket relates to an issue reported by (575)679-5357x44829. The affected client has IP address 9468:d568:5c7e:3ece:55c2:8542:2c96:8ca1 and client ID 79dbb385-04e2-43ca-a6ec-dbd0ca04b741.']\n",
    "ner_data = [[\n",
    "  {\n",
    "    \"label\": \"ip\",\n",
    "    \"start\": 1,\n",
    "    \"end\": 13,\n",
    "    \"value\": \"80.97.168.58\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"login\",\n",
    "    \"start\": 16,\n",
    "    \"end\": 29,\n",
    "    \"value\": \"gorshkovnikon\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"fio\",\n",
    "    \"start\": 31,\n",
    "    \"end\": 57,\n",
    "    \"value\": \"Тимофеев Серафим Антонович\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"email\",\n",
    "    \"start\": 67,\n",
    "    \"end\": 87,\n",
    "    \"value\": \"viktor15@example.net\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"password\",\n",
    "    \"start\": 95,\n",
    "    \"end\": 105,\n",
    "    \"value\": \"_7Ys%IVQp2\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"phone\",\n",
    "    \"start\": 113,\n",
    "    \"end\": 128,\n",
    "    \"value\": \"8 826 587 31 88\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"address\",\n",
    "    \"start\": 135,\n",
    "    \"end\": 187,\n",
    "    \"value\": \"к. Армавир, наб. Грибоедова, д. 9/3 стр. 5/3, 937143\"\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"org\",\n",
    "    \"start\": 193,\n",
    "    \"end\": 213,\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"ipv6\",\n",
    "    \"start\": 219,\n",
    "    \"end\": 256,\n",
    "    \"value\": \"64be:ec33:33f1:1207:5d95:7f1:8710:a5a\"\n",
    "  }\n",
    "],\n",
    "[{'label': 'login', 'start': 38, 'end': 47, 'value': 'jeffrey97'},\n",
    " {'label': 'org', 'start': 66, 'end': 75, 'value': 'Hill-Hall'},\n",
    " {'label': 'phone', 'start': 120, 'end': 139, 'value': '(575)679-5357x44829'},\n",
    " {'label': 'ipv6',\n",
    "  'start': 176,\n",
    "  'end': 215,\n",
    "  'value': '9468:d568:5c7e:3ece:55c2:8542:2c96:8ca1'}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459bcd45-832f-4303-9fbf-a846195ac2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:31:48.615870Z",
     "iopub.status.busy": "2025-07-23T12:31:48.615489Z",
     "iopub.status.idle": "2025-07-23T12:32:00.707471Z",
     "shell.execute_reply": "2025-07-23T12:32:00.705956Z",
     "shell.execute_reply.started": "2025-07-23T12:31:48.615851Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepared_data(data_log,ner_data,unique_labels):\n",
    "    df = pd.DataFrame({\n",
    "    \"sentence\": data_log,\n",
    "    \"ner\": ner_data,\n",
    "  })\n",
    "  #Creat label dictionary\n",
    "    unique_labels_ner = [\"O\"] + sorted([f\"B-{e}\" for e in unique_labels] + [f\"I-{e}\" for e in unique_labels])\n",
    "    label2id = {label: idx for idx, label in enumerate(unique_labels_ner)}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "  \n",
    "  # Tokenize text\n",
    "    tokenized = df[\"sentence\"].apply(lambda x: tokenizer.encode_plus(\n",
    "        x,\n",
    "        add_special_tokens=True,  # Adds [CLS] and [SEP]\n",
    "        max_length=256,           # Pad/truncate to max length\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'       # Return PyTorch tensors\n",
    "    ))\n",
    "    df[\"input_ids\"] = tokenized.apply(lambda x: x[\"input_ids\"].squeeze(0))\n",
    "    df[\"attention_mask\"] = tokenized.apply(lambda x: x[\"attention_mask\"].squeeze(0))\n",
    "    df[\"offset_mapping\"] = tokenized.apply(lambda x: x[\"offset_mapping\"].squeeze(0))\n",
    "    return df,label2id,id2label,unique_labels_ner\n",
    "\n",
    "df,label2id,id2label,unique_labels_ner = prepared_data(data_train,ner_train,unique_labels)\n",
    "df_val,_,_,_ = prepared_data(data_val,ner_val,unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a88f4d37-6047-4f55-8abe-02ff384ca594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:32:01.854742Z",
     "iopub.status.busy": "2025-07-23T12:32:01.854347Z",
     "iopub.status.idle": "2025-07-23T12:32:01.890934Z",
     "shell.execute_reply": "2025-07-23T12:32:01.890197Z",
     "shell.execute_reply.started": "2025-07-23T12:32:01.854721Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mark_label(labels,idx,label2id,label_ner,start_ner =-1,start_token = 1):\n",
    "    if (start_token < start_ner):\n",
    "        labels[idx] = label2id[f\"B-{label_ner}\"]\n",
    "    else:\n",
    "        labels[idx] = label2id[f\"I-{label_ner}\"]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d6e2b2d-9efc-4c9e-9698-aa5a364768b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:32:01.892179Z",
     "iopub.status.busy": "2025-07-23T12:32:01.891756Z",
     "iopub.status.idle": "2025-07-23T12:35:19.107861Z",
     "shell.execute_reply": "2025-07-23T12:35:19.106728Z",
     "shell.execute_reply.started": "2025-07-23T12:32:01.892153Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 84.32it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_labels(ners,offsets,label2id):\n",
    "    total_labels = []\n",
    "    for ner,offset in tqdm(zip(ners,offsets)):\n",
    "        labels = [label2id[\"O\"]] * len(offset)\n",
    "        idx = 0\n",
    "        for item in offset:\n",
    "            start_token = item[0]\n",
    "            end_token = item[1]\n",
    "            if start_token == 0 and end_token == 0:\n",
    "                labels[idx] = -100 \n",
    "            else:\n",
    "                for entity in ner:\n",
    "                    start_ner = entity[\"start\"]\n",
    "                    end_ner = entity[\"end\"]\n",
    "                    label_ner = entity[\"label\"]\n",
    "                    if end_token >= start_ner and end_token < end_ner:\n",
    "                        labels = mark_label(labels,idx,label2id,label_ner,start_ner,start_token)\n",
    "                        break\n",
    "                    elif end_ner > (start_token +1) and start_token > start_ner:\n",
    "                        labels = mark_label(labels,idx,label2id,label_ner)\n",
    "                        break\n",
    "            idx +=1\n",
    "        total_labels.append(labels)\n",
    "    return total_labels\n",
    "df['labels'] = create_labels(df[\"ner\"],df[\"offset_mapping\"],label2id)\n",
    "df_val['labels'] = create_labels(df_val[\"ner\"],df_val[\"offset_mapping\"],label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd328a0-7260-454e-aa37-5af3847b4db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.109551Z",
     "iopub.status.busy": "2025-07-23T12:35:19.109207Z",
     "iopub.status.idle": "2025-07-23T12:35:19.134345Z",
     "shell.execute_reply": "2025-07-23T12:35:19.133591Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.109530Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'fio', 'start': 185, 'end': 197, 'value': 'Amber Bailey'},\n",
       " {'label': 'address',\n",
       "  'start': 198,\n",
       "  'end': 230,\n",
       "  'value': 'Unit 3350 Box 4909, DPO AA 96340'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ner'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "79734cb3-c3bf-4d21-8fba-374865b77cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.135723Z",
     "iopub.status.busy": "2025-07-23T12:35:19.135413Z",
     "iopub.status.idle": "2025-07-23T12:35:19.147439Z",
     "shell.execute_reply": "2025-07-23T12:35:19.146665Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.135702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'127.0.0.1 - cynthiagraham [22/Jul/2025:15:56:14 ] \"OPTIONS search HTTP/2\" 502 230057 \"http://walters.com/explore/list/categoryregister.asp\" \"Mozilla/5.0 (Macintosh; U; PPC Mac OS X 10_9_6 rv:3.0; nso-ZA) AppleWebKit/534.33.4 (KHTML, like Gecko) Version/5.0.1 Safari/534.33.4\" 55d7e231-cb01-4718-89ec-623d6e6f7c71 c0fe:5627:a21d:4355:9882:c12d:c999:aa3c 7630 Taylor Extension, East Lisa, RI 45839 (264)562-0255x461 epotter@hotmail.com 36391'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beb1e295-87ae-482e-923a-f30697b7128d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.148496Z",
     "iopub.status.busy": "2025-07-23T12:35:19.148191Z",
     "iopub.status.idle": "2025-07-23T12:35:19.930944Z",
     "shell.execute_reply": "2025-07-23T12:35:19.930082Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.148477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>ner</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>offset_mapping</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.0.0.1 - holly47 [22/Jul/2025:15:56:14 ] \"D...</td>\n",
       "      <td>[{'label': 'ipv6', 'start': 303, 'end': 339, '...</td>\n",
       "      <td>[tensor(0), tensor(427), tensor(25691), tensor...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.0.0.1 - kendraday [22/Jul/2025:15:56:14 ] ...</td>\n",
       "      <td>[{'label': 'fio', 'start': 185, 'end': 197, 'v...</td>\n",
       "      <td>[tensor(0), tensor(427), tensor(25691), tensor...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167.130.254.131 - - [22/Jul/2025:15:56:14 ] \"P...</td>\n",
       "      <td>[{'label': 'ip', 'start': 1, 'end': 16, 'value...</td>\n",
       "      <td>[tensor(0), tensor(20035), tensor(5), tensor(1...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(3)...</td>\n",
       "      <td>[-100, 4, 13, 13, 13, 13, 13, 13, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.178.165.218 - Kimberly Reeves [22/Jul/2025:...</td>\n",
       "      <td>[{'label': 'ip', 'start': 1, 'end': 15, 'value...</td>\n",
       "      <td>[tensor(0), tensor(4426), tensor(5), tensor(17...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 4, 13, 13, 13, 13, 13, 13, 13, 0, 3, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127.0.0.1 - Catherine Bailey ([22/Jul/2025:15:...</td>\n",
       "      <td>[{'label': 'fio', 'start': 13, 'end': 29, 'val...</td>\n",
       "      <td>[tensor(0), tensor(427), tensor(25691), tensor...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 3, 12, 12, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>127.0.0.1 - sara16 (Traci Vega) [22/Jul/2025:1...</td>\n",
       "      <td>[{'label': 'login', 'start': 13, 'end': 19, 'v...</td>\n",
       "      <td>[tensor(0), tensor(427), tensor(25691), tensor...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 6, 15, 15, 0, 3, 12, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.35.90.59 - karl_2016 [22/Jul/2025:15:56:15 ]...</td>\n",
       "      <td>[{'label': 'ip', 'start': 1, 'end': 11, 'value...</td>\n",
       "      <td>[tensor(0), tensor(1897), tensor(3050), tensor...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 4, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>170.29.149.208 - Анжела Львовна Молчанова НПО ...</td>\n",
       "      <td>[{'label': 'ip', 'start': 1, 'end': 15, 'value...</td>\n",
       "      <td>[tensor(0), tensor(7182), tensor(5), tensor(24...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(3)...</td>\n",
       "      <td>[-100, 4, 13, 13, 13, 13, 13, 13, 0, 3, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>127.0.0.1 - alla98 [15:56:16] \"OPTIONS categor...</td>\n",
       "      <td>[{'label': 'login', 'start': 13, 'end': 19, 'v...</td>\n",
       "      <td>[tensor(0), tensor(427), tensor(25691), tensor...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(2)...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 6, 15, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>199.40.168.7 - Michele Harris - nathanpham@yah...</td>\n",
       "      <td>[{'label': 'ip', 'start': 1, 'end': 13, 'value...</td>\n",
       "      <td>[tensor(0), tensor(20331), tensor(5), tensor(1...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "      <td>[[tensor(0), tensor(0)], [tensor(0), tensor(3)...</td>\n",
       "      <td>[-100, 4, 13, 13, 13, 13, 13, 13, 0, 3, 12, 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  127.0.0.1 - holly47 [22/Jul/2025:15:56:14 ] \"D...   \n",
       "1  127.0.0.1 - kendraday [22/Jul/2025:15:56:14 ] ...   \n",
       "2  167.130.254.131 - - [22/Jul/2025:15:56:14 ] \"P...   \n",
       "3  99.178.165.218 - Kimberly Reeves [22/Jul/2025:...   \n",
       "4  127.0.0.1 - Catherine Bailey ([22/Jul/2025:15:...   \n",
       "5  127.0.0.1 - sara16 (Traci Vega) [22/Jul/2025:1...   \n",
       "6  7.35.90.59 - karl_2016 [22/Jul/2025:15:56:15 ]...   \n",
       "7  170.29.149.208 - Анжела Львовна Молчанова НПО ...   \n",
       "8  127.0.0.1 - alla98 [15:56:16] \"OPTIONS categor...   \n",
       "9  199.40.168.7 - Michele Harris - nathanpham@yah...   \n",
       "\n",
       "                                                 ner  \\\n",
       "0  [{'label': 'ipv6', 'start': 303, 'end': 339, '...   \n",
       "1  [{'label': 'fio', 'start': 185, 'end': 197, 'v...   \n",
       "2  [{'label': 'ip', 'start': 1, 'end': 16, 'value...   \n",
       "3  [{'label': 'ip', 'start': 1, 'end': 15, 'value...   \n",
       "4  [{'label': 'fio', 'start': 13, 'end': 29, 'val...   \n",
       "5  [{'label': 'login', 'start': 13, 'end': 19, 'v...   \n",
       "6  [{'label': 'ip', 'start': 1, 'end': 11, 'value...   \n",
       "7  [{'label': 'ip', 'start': 1, 'end': 15, 'value...   \n",
       "8  [{'label': 'login', 'start': 13, 'end': 19, 'v...   \n",
       "9  [{'label': 'ip', 'start': 1, 'end': 13, 'value...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [tensor(0), tensor(427), tensor(25691), tensor...   \n",
       "1  [tensor(0), tensor(427), tensor(25691), tensor...   \n",
       "2  [tensor(0), tensor(20035), tensor(5), tensor(1...   \n",
       "3  [tensor(0), tensor(4426), tensor(5), tensor(17...   \n",
       "4  [tensor(0), tensor(427), tensor(25691), tensor...   \n",
       "5  [tensor(0), tensor(427), tensor(25691), tensor...   \n",
       "6  [tensor(0), tensor(1897), tensor(3050), tensor...   \n",
       "7  [tensor(0), tensor(7182), tensor(5), tensor(24...   \n",
       "8  [tensor(0), tensor(427), tensor(25691), tensor...   \n",
       "9  [tensor(0), tensor(20331), tensor(5), tensor(1...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "1  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "2  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "3  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "4  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "5  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "6  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "7  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "8  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "9  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n",
       "\n",
       "                                      offset_mapping  \\\n",
       "0  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "1  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "2  [[tensor(0), tensor(0)], [tensor(0), tensor(3)...   \n",
       "3  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "4  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "5  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "6  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "7  [[tensor(0), tensor(0)], [tensor(0), tensor(3)...   \n",
       "8  [[tensor(0), tensor(0)], [tensor(0), tensor(2)...   \n",
       "9  [[tensor(0), tensor(0)], [tensor(0), tensor(3)...   \n",
       "\n",
       "                                              labels  \n",
       "0  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [-100, 4, 13, 13, 13, 13, 13, 13, 0, 0, 0, 0, ...  \n",
       "3  [-100, 4, 13, 13, 13, 13, 13, 13, 13, 0, 3, 12...  \n",
       "4  [-100, 0, 0, 0, 0, 0, 3, 12, 12, 0, 0, 0, 0, 0...  \n",
       "5  [-100, 0, 0, 0, 0, 0, 6, 15, 15, 0, 3, 12, 12,...  \n",
       "6  [-100, 4, 13, 13, 13, 13, 13, 0, 0, 0, 0, 0, 0...  \n",
       "7  [-100, 4, 13, 13, 13, 13, 13, 13, 0, 3, 12, 12...  \n",
       "8  [-100, 0, 0, 0, 0, 0, 6, 15, 0, 0, 0, 0, 0, 0,...  \n",
       "9  [-100, 4, 13, 13, 13, 13, 13, 13, 0, 3, 12, 12...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33dd23cf-ef5c-4814-91ed-e3c2624f653c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.933360Z",
     "iopub.status.busy": "2025-07-23T12:35:19.933037Z",
     "iopub.status.idle": "2025-07-23T12:35:19.947435Z",
     "shell.execute_reply": "2025-07-23T12:35:19.946649Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.933338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ipv6',\n",
       "  'start': 314,\n",
       "  'end': 353,\n",
       "  'value': 'c0fe:5627:a21d:4355:9882:c12d:c999:aa3c'},\n",
       " {'label': 'address',\n",
       "  'start': 354,\n",
       "  'end': 396,\n",
       "  'value': '7630 Taylor Extension, East Lisa, RI 45839'},\n",
       " {'label': 'phone', 'start': 397, 'end': 414, 'value': '(264)562-0255x461'},\n",
       " {'label': 'email', 'start': 415, 'end': 434, 'value': 'epotter@hotmail.com'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ner'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a95f6c-0f65-4d7f-8f0b-ecf2b118dd35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.948505Z",
     "iopub.status.busy": "2025-07-23T12:35:19.948173Z",
     "iopub.status.idle": "2025-07-23T12:35:19.980532Z",
     "shell.execute_reply": "2025-07-23T12:35:19.979773Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.948480Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>             → IGNORED, tensor([0, 0])\n",
      "▁12             → O, tensor([0, 2])\n",
      "7.0             → O, tensor([2, 5])\n",
      ".               → O, tensor([5, 6])\n",
      "0.1             → O, tensor([6, 9])\n",
      "▁-              → O, tensor([ 9, 11])\n",
      "▁holl           → O, tensor([11, 16])\n",
      "y               → O, tensor([16, 17])\n",
      "47              → O, tensor([17, 19])\n",
      "▁[              → O, tensor([19, 21])\n",
      "22              → O, tensor([21, 23])\n",
      "/               → O, tensor([23, 24])\n",
      "Jul             → O, tensor([24, 27])\n",
      "/20             → O, tensor([27, 30])\n",
      "25              → O, tensor([30, 32])\n",
      ":15             → O, tensor([32, 35])\n",
      ":               → O, tensor([35, 36])\n",
      "56              → O, tensor([36, 38])\n",
      ":14             → O, tensor([38, 41])\n",
      "▁               → O, tensor([41, 42])\n",
      "]               → O, tensor([42, 43])\n",
      "▁\"              → O, tensor([43, 45])\n",
      "DE              → O, tensor([45, 47])\n",
      "LE              → O, tensor([47, 49])\n",
      "TE              → O, tensor([49, 51])\n",
      "▁main           → O, tensor([51, 56])\n",
      "/               → O, tensor([56, 57])\n",
      "app             → O, tensor([57, 60])\n",
      "▁HTTP           → O, tensor([60, 65])\n",
      "/               → O, tensor([65, 66])\n",
      "1.0             → O, tensor([66, 69])\n",
      "\"               → O, tensor([69, 70])\n",
      "▁50             → O, tensor([70, 73])\n",
      "2               → O, tensor([73, 74])\n",
      "▁64             → O, tensor([74, 77])\n",
      "42              → O, tensor([77, 79])\n",
      "75              → O, tensor([79, 81])\n",
      "▁\"              → O, tensor([81, 83])\n",
      "https           → O, tensor([83, 88])\n",
      "://             → O, tensor([88, 91])\n",
      "www             → O, tensor([91, 94])\n",
      ".               → O, tensor([94, 95])\n",
      "si              → O, tensor([95, 97])\n",
      "mon             → O, tensor([ 97, 100])\n",
      ".               → O, tensor([100, 101])\n",
      "info            → O, tensor([101, 105])\n",
      "/               → O, tensor([105, 106])\n",
      "list            → O, tensor([106, 110])\n",
      "/               → O, tensor([110, 111])\n",
      "main            → O, tensor([111, 115])\n",
      "pri             → O, tensor([115, 118])\n",
      "va              → O, tensor([118, 120])\n",
      "cy              → O, tensor([120, 122])\n",
      ".               → O, tensor([122, 123])\n",
      "html            → O, tensor([123, 127])\n",
      "\"               → O, tensor([127, 128])\n",
      "▁\"              → O, tensor([128, 130])\n",
      "Mo              → O, tensor([130, 132])\n",
      "z               → O, tensor([132, 133])\n",
      "illa            → O, tensor([133, 137])\n",
      "/5              → O, tensor([137, 139])\n",
      ".               → O, tensor([139, 140])\n",
      "0               → O, tensor([140, 141])\n",
      "▁(              → O, tensor([141, 143])\n",
      "iPad            → O, tensor([143, 147])\n",
      ";               → O, tensor([147, 148])\n",
      "▁CPU            → O, tensor([148, 152])\n",
      "▁iPad           → O, tensor([152, 157])\n",
      "▁OS             → O, tensor([157, 160])\n",
      "▁17             → O, tensor([160, 163])\n",
      "_               → O, tensor([163, 164])\n",
      "1               → O, tensor([164, 165])\n",
      "▁like           → O, tensor([165, 170])\n",
      "▁Mac            → O, tensor([170, 174])\n",
      "▁OS             → O, tensor([174, 177])\n",
      "▁X              → O, tensor([177, 179])\n",
      ")               → O, tensor([179, 180])\n",
      "▁Apple          → O, tensor([180, 186])\n",
      "Web             → O, tensor([186, 189])\n",
      "K               → O, tensor([189, 190])\n",
      "it              → O, tensor([190, 192])\n",
      "/               → O, tensor([192, 193])\n",
      "53              → O, tensor([193, 195])\n",
      "3.0             → O, tensor([195, 198])\n",
      "▁(              → O, tensor([198, 200])\n",
      "K               → O, tensor([200, 201])\n",
      "HTML            → O, tensor([201, 205])\n",
      ",               → O, tensor([205, 206])\n",
      "▁like           → O, tensor([206, 211])\n",
      "▁Ge             → O, tensor([211, 214])\n",
      "cko             → O, tensor([214, 217])\n",
      ")               → O, tensor([217, 218])\n",
      "▁F              → O, tensor([218, 220])\n",
      "x               → O, tensor([220, 221])\n",
      "iOS             → O, tensor([221, 224])\n",
      "/1              → O, tensor([224, 226])\n",
      "4.9             → O, tensor([226, 229])\n",
      "o               → O, tensor([229, 230])\n",
      "28              → O, tensor([230, 232])\n",
      "66              → O, tensor([232, 234])\n",
      ".               → O, tensor([234, 235])\n",
      "0               → O, tensor([235, 236])\n",
      "▁Mobile         → O, tensor([236, 243])\n",
      "/15             → O, tensor([243, 246])\n",
      "D               → O, tensor([246, 247])\n",
      "105             → O, tensor([247, 250])\n",
      "▁Safari         → O, tensor([250, 257])\n",
      "/               → O, tensor([257, 258])\n",
      "53              → O, tensor([258, 260])\n",
      "3.0             → O, tensor([260, 263])\n",
      "\"               → O, tensor([263, 264])\n",
      "▁79             → O, tensor([264, 267])\n",
      "be              → O, tensor([267, 269])\n",
      "8               → O, tensor([269, 270])\n",
      "bb              → O, tensor([270, 272])\n",
      "c               → O, tensor([272, 273])\n",
      "-45             → O, tensor([273, 276])\n",
      "ee              → O, tensor([276, 278])\n",
      "-40             → O, tensor([278, 281])\n",
      "1               → O, tensor([281, 282])\n",
      "e               → O, tensor([282, 283])\n",
      "-9              → O, tensor([283, 285])\n",
      "ef              → O, tensor([285, 287])\n",
      "2-              → O, tensor([287, 289])\n",
      "89              → O, tensor([289, 291])\n",
      "ee              → O, tensor([291, 293])\n",
      "500             → O, tensor([293, 296])\n",
      "f               → O, tensor([296, 297])\n",
      "58              → O, tensor([297, 299])\n",
      "58              → O, tensor([299, 301])\n",
      "▁c              → B-ipv6, tensor([301, 303])\n",
      "82              → I-ipv6, tensor([303, 305])\n",
      "2               → I-ipv6, tensor([305, 306])\n",
      ":               → I-ipv6, tensor([306, 307])\n",
      "ff              → I-ipv6, tensor([307, 309])\n",
      "10              → I-ipv6, tensor([309, 311])\n",
      ":25             → I-ipv6, tensor([311, 314])\n",
      "08              → I-ipv6, tensor([314, 316])\n",
      ":               → I-ipv6, tensor([316, 317])\n",
      "ec              → I-ipv6, tensor([317, 319])\n",
      "3               → I-ipv6, tensor([319, 320])\n",
      ":               → I-ipv6, tensor([320, 321])\n",
      "ad              → I-ipv6, tensor([321, 323])\n",
      "1               → I-ipv6, tensor([323, 324])\n",
      ":1              → I-ipv6, tensor([324, 326])\n",
      "a               → I-ipv6, tensor([326, 327])\n",
      "8               → I-ipv6, tensor([327, 328])\n",
      "c               → I-ipv6, tensor([328, 329])\n",
      ":               → I-ipv6, tensor([329, 330])\n",
      "4               → I-ipv6, tensor([330, 331])\n",
      "a               → I-ipv6, tensor([331, 332])\n",
      "7               → I-ipv6, tensor([332, 333])\n",
      "a               → I-ipv6, tensor([333, 334])\n",
      ":               → I-ipv6, tensor([334, 335])\n",
      "750             → I-ipv6, tensor([335, 338])\n",
      "▁9              → B-address, tensor([338, 340])\n",
      "44              → I-address, tensor([340, 342])\n",
      "▁Walt           → I-address, tensor([342, 347])\n",
      "on              → I-address, tensor([347, 349])\n",
      "▁Har            → I-address, tensor([349, 353])\n",
      "bor             → I-address, tensor([353, 356])\n",
      "▁Suite          → I-address, tensor([356, 362])\n",
      "▁6              → I-address, tensor([362, 364])\n",
      "84              → I-address, tensor([364, 366])\n",
      ",               → I-address, tensor([366, 367])\n",
      "▁Martin         → I-address, tensor([367, 374])\n",
      "fur             → I-address, tensor([374, 377])\n",
      "t               → I-address, tensor([377, 378])\n",
      ",               → I-address, tensor([378, 379])\n",
      "▁NY             → I-address, tensor([379, 382])\n",
      "▁05             → I-address, tensor([382, 385])\n",
      "88              → I-address, tensor([385, 387])\n",
      "3               → I-address, tensor([387, 388])\n",
      "▁+1             → B-phone, tensor([388, 391])\n",
      "-8              → I-phone, tensor([391, 393])\n",
      "83              → I-phone, tensor([393, 395])\n",
      "-24             → I-phone, tensor([395, 398])\n",
      "4-              → I-phone, tensor([398, 400])\n",
      "63              → I-phone, tensor([400, 402])\n",
      "02              → I-phone, tensor([402, 404])\n",
      "x               → I-phone, tensor([404, 405])\n",
      "36              → I-phone, tensor([405, 407])\n",
      "28              → I-phone, tensor([407, 409])\n",
      "▁mo             → B-email, tensor([409, 412])\n",
      "nica            → I-email, tensor([412, 416])\n",
      "smith           → I-email, tensor([416, 421])\n",
      "@               → I-email, tensor([421, 422])\n",
      "hot             → I-email, tensor([422, 425])\n",
      "mail            → I-email, tensor([425, 429])\n",
      ".               → I-email, tensor([429, 430])\n",
      "com             → I-email, tensor([430, 433])\n",
      "▁157            → O, tensor([433, 437])\n",
      "59              → O, tensor([437, 439])\n",
      "</s>            → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n",
      "<pad>           → IGNORED, tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "def test_tokens(labels,input_ids,offset):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    token_labels = [id2label[l] if l != -100 else \"IGNORED\" for l in labels]\n",
    "    for t, l, o in zip(tokens, token_labels,offset):\n",
    "        print(f\"{t:15} → {l}, {o}\")\n",
    "test_tokens(df['labels'][0],df['input_ids'][0],df[\"offset_mapping\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276de224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ccc884c-91f6-4f47-8d30-660b2782a624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.981872Z",
     "iopub.status.busy": "2025-07-23T12:35:19.981307Z",
     "iopub.status.idle": "2025-07-23T12:35:19.994208Z",
     "shell.execute_reply": "2025-07-23T12:35:19.993484Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.981850Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenClassifierHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels):\n",
    "        \"\"\"\n",
    "        Classification head for token-level predictions.\n",
    "        \"\"\"\n",
    "        super(TokenClassifierHead, self).__init__()\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: tensor of shape [batch_size, seq_len, hidden_size]\n",
    "        Returns:\n",
    "            logits: tensor of shape [batch_size, seq_len, num_labels]\n",
    "        \"\"\"\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2dbf2de-82ad-4932-9016-12f89574a0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:19.995851Z",
     "iopub.status.busy": "2025-07-23T12:35:19.995030Z",
     "iopub.status.idle": "2025-07-23T12:35:20.027750Z",
     "shell.execute_reply": "2025-07-23T12:35:20.026979Z",
     "shell.execute_reply.started": "2025-07-23T12:35:19.995831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTForNER(nn.Module):\n",
    "    def __init__(self, model, num_labels):\n",
    "        \"\"\"\n",
    "        BERT + token classification head for NER.\n",
    "        \"\"\"\n",
    "        super(BERTForNER, self).__init__()\n",
    "        self.bert = model\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.classifier = TokenClassifierHead(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: [batch_size, seq_len]\n",
    "            attention_mask: [batch_size, seq_len]\n",
    "            token_type_ids: [batch_size, seq_len]\n",
    "        Returns:\n",
    "            logits: [batch_size, seq_len, num_labels]\n",
    "        \"\"\"\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        # Get all token embeddings\n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # Predict logits for each token\n",
    "        logits = self.classifier(sequence_output)  # [batch_size, seq_len, num_labels]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01ae67ae-6e61-495e-893c-e3976ed91449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:20.028855Z",
     "iopub.status.busy": "2025-07-23T12:35:20.028528Z",
     "iopub.status.idle": "2025-07-23T12:35:20.059655Z",
     "shell.execute_reply": "2025-07-23T12:35:20.058876Z",
     "shell.execute_reply.started": "2025-07-23T12:35:20.028836Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, input_ids,attention_mask, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encodings: tokenizer output (input_ids, attention_mask, etc.)\n",
    "            labels: list of BIO tag IDs aligned with tokens\n",
    "        \"\"\"\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item ={}\n",
    "        item['input_ids'] =  torch.tensor(self.input_ids[idx])\n",
    "        item['attention_mask']  = torch.tensor(self.attention_mask[idx])\n",
    "        item[\"labels\"] =  torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b05f831-b740-4663-a134-24f254a4c349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:35:23.222221Z",
     "iopub.status.busy": "2025-07-23T12:35:23.221674Z",
     "iopub.status.idle": "2025-07-23T12:35:23.258575Z",
     "shell.execute_reply": "2025-07-23T12:35:23.257667Z",
     "shell.execute_reply.started": "2025-07-23T12:35:23.222201Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, df, df_val, unique_labels_ner, epochs):\n",
    "    num_labels = len(unique_labels_ner)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataset = NERDataset(df['input_ids'], df['attention_mask'], df['labels'])\n",
    "    val_dataset = NERDataset(df_val['input_ids'], df_val['attention_mask'], df_val['labels'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss_train = 0.0\n",
    "\n",
    "        for b_n, batch in tqdm(enumerate(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "\n",
    "            loss = criterion(\n",
    "                logits.view(-1, num_labels),  # Flatten\n",
    "                labels.view(-1)\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss_train += loss.item()\n",
    "            if b_n % 100 == 0:\n",
    "                print('train_loss:', loss.item())\n",
    "                model.eval()\n",
    "                total_loss_val = 0.0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for batch in val_loader:\n",
    "                        input_ids = batch[\"input_ids\"].to(device)\n",
    "                        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                        logits = model(input_ids, attention_mask)\n",
    "\n",
    "                        loss = criterion(\n",
    "                            logits.view(-1, num_labels),\n",
    "                            labels.view(-1)\n",
    "                        )\n",
    "                        total_loss_val += loss.item()\n",
    "\n",
    "                avg_loss_val = total_loss_val / len(val_loader)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs} batch {b_n}/{len(train_loader)} - Loss_val: {avg_loss_val:.4f}\")\n",
    "\n",
    "        \n",
    "        avg_loss_train = total_loss_train / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_loss_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                logits = model(input_ids, attention_mask)\n",
    "\n",
    "                loss = criterion(\n",
    "                    logits.view(-1, num_labels),\n",
    "                    labels.view(-1)\n",
    "                )\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "        avg_loss_val = total_loss_val / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss_train: {avg_loss_train:.4f}, Loss_val: {avg_loss_val:.4f}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c10c7-134e-4cd6-91a9-746061fdb0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:37:23.743257Z",
     "iopub.status.busy": "2025-07-23T12:37:23.742775Z",
     "iopub.status.idle": "2025-07-23T12:37:24.752374Z",
     "shell.execute_reply": "2025-07-23T12:37:24.751402Z",
     "shell.execute_reply.started": "2025-07-23T12:37:23.743235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTForNER(base_model, len(unique_labels_ner)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e60c4-554c-45e0-ab24-1476d34a3151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:37:27.009148Z",
     "iopub.status.busy": "2025-07-23T12:37:27.008781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 3.342041492462158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:14, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 batch0/179 - Loss_val: 1.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [05:55,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.6870251893997192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [06:09,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 batch100/179 - Loss_val: 1.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [07:08,  3.46s/it]"
     ]
    }
   ],
   "source": [
    "train(model,df,df_val,unique_labels_ner,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82c3e4-13dc-4e4f-8c40-f556e9332192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model_test, \"/home/jupyter/datasphere/project/model/bertner_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b006dc10-b0df-4d7b-bc23-0b11f7b92a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T17:47:46.062941Z",
     "iopub.status.busy": "2025-07-22T17:47:46.061961Z",
     "iopub.status.idle": "2025-07-22T17:47:46.088740Z",
     "shell.execute_reply": "2025-07-22T17:47:46.087814Z",
     "shell.execute_reply.started": "2025-07-22T17:47:46.062896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200.168.1.1 - aguljaeva - Ермил Арсенович Жуков [22/Jul/2025:15:56:19 ] \"POST http://www.bankovski.info/ HTTP/1.1/200\" 594358 \"http://www.rao.biz/app/search/postssearch.htm\" \"Mozilla/5.0 (compatible; MSIE 8.0; Windows CE; Trident/4.0)\" 594358 oao.biz д. Саранск, бул. Алтайский, д. 530, 529045'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59121e5f-0ec1-4740-ba92-e5dc3a8eea0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T17:49:28.756645Z",
     "iopub.status.busy": "2025-07-22T17:49:28.755529Z",
     "iopub.status.idle": "2025-07-22T17:49:28.778211Z",
     "shell.execute_reply": "2025-07-22T17:49:28.777286Z",
     "shell.execute_reply.started": "2025-07-22T17:49:28.756598Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, id2label, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Run NER prediction on raw text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw input text.\n",
    "        model (nn.Module): Your trained BERTForNER model.\n",
    "        tokenizer: Hugging Face tokenizer.\n",
    "        id2label (dict): Mapping from label IDs to label names.\n",
    "        device (str): \"cpu\" or \"cuda\".\n",
    "    Returns:\n",
    "        List of (token, predicted_label)\n",
    "    \"\"\"\n",
    "    # Tokenize input text\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,  # Adds [CLS] and [SEP]\n",
    "        max_length=512,           # Pad/truncate to max length\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'       # Return PyTorch tensors\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        predictions = torch.argmax(logits, dim=-1)  # [batch_size, seq_len]\n",
    "\n",
    "    # Convert IDs to tokens and labels\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
    "\n",
    "    # Filter out special tokens ([CLS], [SEP], [PAD])\n",
    "    filtered_results = []\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if token not in tokenizer.all_special_tokens:\n",
    "            filtered_results.append((token, label))\n",
    "\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f6d575-8d10-466e-a288-d6dcb27ae098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T17:49:40.814495Z",
     "iopub.status.busy": "2025-07-22T17:49:40.813578Z",
     "iopub.status.idle": "2025-07-22T17:49:41.062092Z",
     "shell.execute_reply": "2025-07-22T17:49:41.061272Z",
     "shell.execute_reply.started": "2025-07-22T17:49:40.814453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_results = predict(df_test['sentence'][0], model_test, tokenizer, id2label, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdea15a4-7d31-481c-9f42-efd23186bf57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T17:49:45.993349Z",
     "iopub.status.busy": "2025-07-22T17:49:45.992393Z",
     "iopub.status.idle": "2025-07-22T17:49:46.026351Z",
     "shell.execute_reply": "2025-07-22T17:49:46.025523Z",
     "shell.execute_reply.started": "2025-07-22T17:49:45.993308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁200', 'O'),\n",
       " ('.', 'O'),\n",
       " ('168', 'O'),\n",
       " ('.1.1', 'O'),\n",
       " ('▁-', 'O'),\n",
       " ('▁a', 'O'),\n",
       " ('gul', 'O'),\n",
       " ('ja', 'O'),\n",
       " ('eva', 'O'),\n",
       " ('▁-', 'O'),\n",
       " ('▁Ер', 'O'),\n",
       " ('мил', 'O'),\n",
       " ('▁Арсен', 'O'),\n",
       " ('ович', 'O'),\n",
       " ('▁Жу', 'O'),\n",
       " ('ков', 'O'),\n",
       " ('▁[', 'O'),\n",
       " ('22', 'O'),\n",
       " ('/', 'O'),\n",
       " ('Jul', 'O'),\n",
       " ('/20', 'O'),\n",
       " ('25', 'O'),\n",
       " (':15', 'O'),\n",
       " (':', 'O'),\n",
       " ('56', 'O'),\n",
       " (':', 'O'),\n",
       " ('19', 'O'),\n",
       " ('▁', 'O'),\n",
       " (']', 'O'),\n",
       " ('▁\"', 'O'),\n",
       " ('P', 'O'),\n",
       " ('OST', 'O'),\n",
       " ('▁http', 'O'),\n",
       " ('://', 'O'),\n",
       " ('www', 'O'),\n",
       " ('.', 'O'),\n",
       " ('ban', 'O'),\n",
       " ('kov', 'O'),\n",
       " ('ski', 'O'),\n",
       " ('.', 'O'),\n",
       " ('info', 'O'),\n",
       " ('/', 'O'),\n",
       " ('▁HTTP', 'O'),\n",
       " ('/', 'O'),\n",
       " ('1.1', 'O'),\n",
       " ('/', 'O'),\n",
       " ('200', 'O'),\n",
       " ('\"', 'O'),\n",
       " ('▁59', 'O'),\n",
       " ('43', 'O'),\n",
       " ('58', 'O'),\n",
       " ('▁\"', 'O'),\n",
       " ('http', 'O'),\n",
       " ('://', 'O'),\n",
       " ('www', 'O'),\n",
       " ('.', 'O'),\n",
       " ('ra', 'O'),\n",
       " ('o', 'O'),\n",
       " ('.', 'O'),\n",
       " ('bi', 'O'),\n",
       " ('z', 'O'),\n",
       " ('/', 'O'),\n",
       " ('app', 'O'),\n",
       " ('/', 'O'),\n",
       " ('search', 'O'),\n",
       " ('/', 'O'),\n",
       " ('post', 'O'),\n",
       " ('s', 'O'),\n",
       " ('search', 'O'),\n",
       " ('.', 'O'),\n",
       " ('h', 'O'),\n",
       " ('t', 'O'),\n",
       " ('m', 'O'),\n",
       " ('\"', 'O'),\n",
       " ('▁\"', 'O'),\n",
       " ('Mo', 'O'),\n",
       " ('z', 'O'),\n",
       " ('illa', 'O'),\n",
       " ('/5', 'O'),\n",
       " ('.', 'O'),\n",
       " ('0', 'O'),\n",
       " ('▁(', 'O'),\n",
       " ('com', 'O'),\n",
       " ('pati', 'O'),\n",
       " ('ble', 'O'),\n",
       " (';', 'O'),\n",
       " ('▁MSI', 'O'),\n",
       " ('E', 'O'),\n",
       " ('▁8.', 'O'),\n",
       " ('0', 'O'),\n",
       " (';', 'O'),\n",
       " ('▁Windows', 'O'),\n",
       " ('▁CE', 'O'),\n",
       " (';', 'O'),\n",
       " ('▁Tri', 'O'),\n",
       " ('dent', 'O'),\n",
       " ('/', 'O'),\n",
       " ('4.0', 'O'),\n",
       " (')', 'O'),\n",
       " ('\"', 'O'),\n",
       " ('▁59', 'O'),\n",
       " ('43', 'O'),\n",
       " ('58', 'O'),\n",
       " ('▁o', 'O'),\n",
       " ('a', 'O'),\n",
       " ('o', 'O'),\n",
       " ('.', 'O'),\n",
       " ('bi', 'O'),\n",
       " ('z', 'O'),\n",
       " ('▁д', 'O'),\n",
       " ('.', 'O'),\n",
       " ('▁Сара', 'O'),\n",
       " ('н', 'O'),\n",
       " ('ск', 'O'),\n",
       " (',', 'O'),\n",
       " ('▁бул', 'O'),\n",
       " ('.', 'O'),\n",
       " ('▁', 'O'),\n",
       " ('Алтай', 'O'),\n",
       " ('ский', 'O'),\n",
       " (',', 'O'),\n",
       " ('▁д', 'O'),\n",
       " ('.', 'O'),\n",
       " ('▁5', 'O'),\n",
       " ('30', 'O'),\n",
       " (',', 'O'),\n",
       " ('▁5', 'O'),\n",
       " ('290', 'O'),\n",
       " ('45', 'O')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22012563-efc4-4220-a604-7cbc7ddcf426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
